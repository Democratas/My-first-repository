{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Seq2seq으로 번역기 만들기\n",
    "\n",
    "**Seq2seq 기반 번역기를 직접 만들어보며 구조를 이해해 본다. Attention 기법을 추가하여 성능을 높여볼 수 있다. 영어-스페인어 말뭉치와 한국어-영어 말뭉치를 활용해 본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1. Seq2seq 기반 번역기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir -p ~/aiffel/s2s_translation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n",
    "\n",
    "print(\"완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n",
      "2654208/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 118964\n",
      "Example:\n",
      ">> Go.\tVe.\n",
      ">> Wait.\tEsperen.\n",
      ">> Hug me.\tAbrázame.\n",
      ">> No way!\t¡Ni cagando!\n",
      ">> Call me.\tLlamame.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: go away !\n",
      "Spanish: <start> salga de aqu ! <end>\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for pair in raw[:num_examples]:\n",
    "    eng, spa = pair.split(\"\\t\")\n",
    "\n",
    "    enc_corpus.append(preprocess_sentence(eng))\n",
    "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
    "\n",
    "print(\"English:\", enc_corpus[100])   # go away !\n",
    "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 4931\n",
      "Spanish Vocab Size: 8893\n"
     ]
    }
   ],
   "source": [
    "# 토큰화하기\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 분리하기\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.2)\n",
    "\n",
    "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 8894)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4. 훈련하기 (1) Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-5. 훈련하기 (2) train_step 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-6. 훈련하기 (3) 훈련 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [01:04<00:00,  5.79it/s, Loss 1.3375]\n",
      "Epoch  2: 100%|██████████| 375/375 [00:43<00:00,  8.59it/s, Loss 0.8777]\n",
      "Epoch  3: 100%|██████████| 375/375 [00:44<00:00,  8.34it/s, Loss 0.6184]\n",
      "Epoch  4: 100%|██████████| 375/375 [00:44<00:00,  8.42it/s, Loss 0.4432]\n",
      "Epoch  5: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.3277]\n",
      "Epoch  6: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.2543]\n",
      "Epoch  7: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.2082]\n",
      "Epoch  8: 100%|██████████| 375/375 [00:44<00:00,  8.39it/s, Loss 0.1797]\n",
      "Epoch  9: 100%|██████████| 375/375 [00:44<00:00,  8.39it/s, Loss 0.1565]\n",
      "Epoch 10: 100%|██████████| 375/375 [00:44<00:00,  8.40it/s, Loss 0.1400]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [00:44<00:00,  8.35it/s, Loss 0.1305]\n",
      "Test Epoch  1: 100%|██████████| 94/94 [00:14<00:00,  6.49it/s, Test Loss 0.6772]\n",
      "Epoch  2: 100%|██████████| 375/375 [00:44<00:00,  8.39it/s, Loss 0.1194]\n",
      "Test Epoch  2: 100%|██████████| 94/94 [00:04<00:00, 21.64it/s, Test Loss 0.6873]\n",
      "Epoch  3: 100%|██████████| 375/375 [00:44<00:00,  8.40it/s, Loss 0.1150]\n",
      "Test Epoch  3: 100%|██████████| 94/94 [00:04<00:00, 21.74it/s, Test Loss 0.6902]\n",
      "Epoch  4: 100%|██████████| 375/375 [00:44<00:00,  8.41it/s, Loss 0.1071]\n",
      "Test Epoch  4: 100%|██████████| 94/94 [00:04<00:00, 21.75it/s, Test Loss 0.7002]\n",
      "Epoch  5: 100%|██████████| 375/375 [00:44<00:00,  8.40it/s, Loss 0.1037]\n",
      "Test Epoch  5: 100%|██████████| 94/94 [00:04<00:00, 21.76it/s, Test Loss 0.7089]\n",
      "Epoch  6: 100%|██████████| 375/375 [00:44<00:00,  8.39it/s, Loss 0.1012]\n",
      "Test Epoch  6: 100%|██████████| 94/94 [00:04<00:00, 21.69it/s, Test Loss 0.7112]\n",
      "Epoch  7: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.0967]\n",
      "Test Epoch  7: 100%|██████████| 94/94 [00:04<00:00, 21.68it/s, Test Loss 0.7186]\n",
      "Epoch  8: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.0919]\n",
      "Test Epoch  8: 100%|██████████| 94/94 [00:04<00:00, 21.63it/s, Test Loss 0.7198]\n",
      "Epoch  9: 100%|██████████| 375/375 [00:44<00:00,  8.39it/s, Loss 0.0899]\n",
      "Test Epoch  9: 100%|██████████| 94/94 [00:04<00:00, 21.69it/s, Test Loss 0.7317]\n",
      "Epoch 10: 100%|██████████| 375/375 [00:44<00:00,  8.38it/s, Loss 0.0897]\n",
      "Test Epoch 10: 100%|██████████| 94/94 [00:04<00:00, 21.76it/s, Test Loss 0.7390]\n"
     ]
    }
   ],
   "source": [
    "# eval_step() 정의하기\n",
    "# train_step() 이후 eval_step() 진행하도록 소스 수정하기\n",
    "\n",
    "\n",
    "# Define eval_step\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "    \n",
    "        test_loss += test_batch_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: can i have some coffee ?\n",
      "Predicted translation: me pueden dar algo ? <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50/1426363336.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_50/1426363336.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 608,
       "width": 613
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-7. 프로젝트: 한영 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "2.6.0\n",
      "3.4.3\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import tensorflow\n",
    "import matplotlib\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **루브릭**\n",
    ">\n",
    ">|번호|평가문항|상세기준|\n",
    ">|:---:|---|---|\n",
    ">|1|번역기 모델 학습에 필요한 텍스트 데이터 전처리가 한국어 포함하여 잘 이루어졌다.|구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.|\n",
    ">|2|Attentional Seq2seq 모델이 정상적으로 구동된다.|seq2seq 모델 훈련 과정에서 training loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.|\n",
    ">|3|테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느 정도 유사한 영어 번역이 진행됨을 확인하였다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = \"korean-english-park.train.tar.gz\"\n",
    "\n",
    "# Extract the dataset\n",
    "with tarfile.open(dataset_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=\"/aiffel/s2s_translation/\")\n",
    "    \n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time  # Import the time module\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "# Define preprocessing functions\n",
    "def preprocess_sentence_kor(sentence):\n",
    "    mecab = Mecab()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = mecab.morphs(sentence)\n",
    "    return sentence\n",
    "\n",
    "def preprocess_sentence_eng(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Corpus Size: 78941\n",
      "English Corpus Size: 63112\n",
      "Korean Corpus Size: 63112\n"
     ]
    }
   ],
   "source": [
    "# Path to the extracted dataset files\n",
    "data_file_path_en = \"/aiffel/s2s_translation/korean-english-park.train.en\"\n",
    "data_file_path_ko = \"/aiffel/s2s_translation/korean-english-park.train.ko\"\n",
    "\n",
    "# Read and preprocess the dataset\n",
    "cleaned_corpus = []\n",
    "with open(data_file_path_en, 'r', encoding='utf-8') as file_en, open(data_file_path_ko, 'r', encoding='utf-8') as file_ko:\n",
    "    lines_en = file_en.readlines()\n",
    "    lines_ko = file_ko.readlines()\n",
    "    seen = set()\n",
    "    for eng, kor in zip(lines_en, lines_ko):\n",
    "        eng = eng.strip()\n",
    "        kor = kor.strip()\n",
    "        if (eng, kor) not in seen:\n",
    "            cleaned_corpus.append((preprocess_sentence_eng(eng, s_token=True, e_token=True), preprocess_sentence_kor(kor)))\n",
    "            seen.add((eng, kor))\n",
    "\n",
    "print(f\"Cleaned Corpus Size: {len(cleaned_corpus)}\")\n",
    "\n",
    "# Filter sentences with token length greater than 40\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for eng, kor in cleaned_corpus:\n",
    "    if len(eng.split()) <= 40 and len(kor) <= 40:\n",
    "        eng_corpus.append(eng)\n",
    "        kor_corpus.append(' '.join(kor))\n",
    "\n",
    "print(f\"English Corpus Size: {len(eng_corpus)}\")\n",
    "print(f\"Korean Corpus Size: {len(kor_corpus)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length of Target Tensor: 40\n",
      "Max Length of Input Tensor: 40\n",
      "Vocabulary Size of Input Language: 37078\n",
      "Vocabulary Size of Target Language: 38541\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, tokenizer\n",
    "\n",
    "# Tokenize the data\n",
    "input_tensor, inp_lang_tokenizer = tokenize(kor_corpus)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(eng_corpus)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "print(f\"Max Length of Target Tensor: {max_length_targ}\")\n",
    "print(f\"Max Length of Input Tensor: {max_length_inp}\")\n",
    "print(f\"Vocabulary Size of Input Language: {len(inp_lang_tokenizer.word_index)+1}\")\n",
    "print(f\"Vocabulary Size of Target Language: {len(targ_lang_tokenizer.word_index)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 40]), TensorShape([64, 40]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "# Define Attention class\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# Define Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = Attention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "\n",
    "# Initialize encoder and decoder\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.6221\n",
      "Epoch 1 Batch 100 Loss 3.7449\n",
      "Epoch 1 Batch 200 Loss 3.5930\n",
      "Epoch 1 Batch 300 Loss 3.4687\n",
      "Epoch 1 Batch 400 Loss 3.3661\n",
      "Epoch 1 Batch 500 Loss 3.3177\n",
      "Epoch 1 Batch 600 Loss 3.2817\n",
      "Epoch 1 Batch 700 Loss 3.2351\n",
      "Epoch 1 Batch 800 Loss 3.3417\n",
      "Epoch 1 Batch 900 Loss 3.4654\n",
      "Epoch 1 Loss 3.5773\n",
      "Time taken for 1 epoch 672.9268755912781 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.2214\n",
      "Epoch 2 Batch 100 Loss 3.4401\n",
      "Epoch 2 Batch 200 Loss 3.3326\n",
      "Epoch 2 Batch 300 Loss 3.0043\n",
      "Epoch 2 Batch 400 Loss 2.9299\n",
      "Epoch 2 Batch 500 Loss 2.8697\n",
      "Epoch 2 Batch 600 Loss 3.0936\n",
      "Epoch 2 Batch 700 Loss 2.9209\n",
      "Epoch 2 Batch 800 Loss 3.2065\n",
      "Epoch 2 Batch 900 Loss 2.9308\n",
      "Epoch 2 Loss 3.1130\n",
      "Time taken for 1 epoch 640.9734182357788 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.8750\n",
      "Epoch 3 Batch 100 Loss 2.9528\n",
      "Epoch 3 Batch 200 Loss 2.9125\n",
      "Epoch 3 Batch 300 Loss 2.8074\n",
      "Epoch 3 Batch 400 Loss 2.6851\n",
      "Epoch 3 Batch 500 Loss 2.9742\n",
      "Epoch 3 Batch 600 Loss 2.6766\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42/114920315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Wrong number or type of arguments for overloaded function 'Tagger_parse'.\n  Possible C/C++ prototypes are:\n    MeCab::Tagger::parse(MeCab::Model const &,MeCab::Lattice *)\n    MeCab::Tagger::parse(MeCab::Lattice *) const\n    MeCab::Tagger::parse(char const *)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42/1383808305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"오바마는 대통령이다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_42/1383808305.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted translation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_42/1383808305.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sentence_kor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/MeCab.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0m__getattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Wrong number or type of arguments for overloaded function 'Tagger_parse'.\n  Possible C/C++ prototypes are:\n    MeCab::Tagger::parse(MeCab::Model const &,MeCab::Lattice *)\n    MeCab::Tagger::parse(MeCab::Lattice *) const\n    MeCab::Tagger::parse(char const *)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(sentence):\n",
    "    attention = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence_kor(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in mecab.morphs(sentence)]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    enc_out, enc_hidden = encoder(inputs, encoder.initialize_hidden_state())\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence):\n",
    "    result, sentence, attention = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention = attention[:len(result.split()), :len(mecab.morphs(sentence))]\n",
    "    plot_attention(attention, mecab.morphs(sentence), result.split(' '))\n",
    "\n",
    "translate(\"오바마는 대통령이다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예문 ##\n",
    "K1) 오바마는 대통령이다.\n",
    "K2) 시민들은 도시 속에 산다.\n",
    "K3) 커피는 필요 없다.\n",
    "K4) 일곱 명의 사망자가 발생했다.\n",
    "\n",
    "### 제출 ##\n",
    "E1) obama is the president . <end>\n",
    "E2) people are victims of the city . <end>\n",
    "E2) the price is not enough . <end>\n",
    "E2) seven people have died . <end>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
