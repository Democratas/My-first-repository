{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f830345",
   "metadata": {},
   "source": [
    "# Main Quest의 답은 맨 아래에 있습니다! \n",
    "## (위쪽은 Transformer 알고리즘을 분석하고 관련 블럭을 불러오기 위함 입니다!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f55fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627df771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe2fb0",
   "metadata": {},
   "source": [
    "## 2-1. Transformer 전처리 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ee0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 데이터 로드\n",
    "chatbot = pd.read_csv('~/aiffel/transformer_chatbot/data/ChatbotData .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c15d6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb861d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence, num=False):\n",
    "    # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (가-힣, a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    if num == False: # 숫자제거\n",
    "        sentence = re.sub(r'[^가-힣a-zA-Z.?!,]', ' ', sentence)\n",
    "    else:\n",
    "        sentence = re.sub(r'[^가-힣0-9a-zA-Z.?!,]', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106432fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리:토큰화\n",
    "questions = chatbot.Q.tolist()\n",
    "answers = chatbot.A.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf8df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡!',\n",
       " '1지망 학교 떨어졌어',\n",
       " '3박4일 놀러가고 싶다',\n",
       " '3박4일 정도 놀러가고 싶다',\n",
       " 'PPL 심하네',\n",
       " 'SD카드 망가졌어',\n",
       " 'SD카드 안돼',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨',\n",
       " 'SNS보면 나만 빼고 다 행복해보여',\n",
       " '가끔 궁금해',\n",
       " '가끔 뭐하는지 궁금해',\n",
       " '가끔은 혼자인게 좋다',\n",
       " '가난한 자의 설움',\n",
       " '가만 있어도 땀난다',\n",
       " '가상화폐 쫄딱 망함',\n",
       " '가스불 켜고 나갔어',\n",
       " '가스불 켜놓고 나온거 같아',\n",
       " '가스비 너무 많이 나왔다.',\n",
       " '가스비 비싼데 감기 걸리겠어',\n",
       " '가스비 장난 아님',\n",
       " '가장 확실한 건 뭘까?',\n",
       " '가족 여행 가기로 했어',\n",
       " '가족 여행 고고',\n",
       " '가족 여행 어디로 가지?',\n",
       " '가족 있어?',\n",
       " '가족관계 알려 줘',\n",
       " '가족끼리 여행간다.',\n",
       " '가족들 보고 싶어',\n",
       " '가족들이랑 서먹해',\n",
       " '가족들이랑 서먹해졌어',\n",
       " '가족들이랑 어디 가지?',\n",
       " '가족들이랑 여행 갈거야',\n",
       " '가족여행 가야지',\n",
       " '가족이 누구야?',\n",
       " '가족이랑 여행 가려고',\n",
       " '가족한테 스트레스 풀었어',\n",
       " '가출할까?',\n",
       " '가출해도 갈 데가 없어',\n",
       " '간만에 떨리니까 좋더라',\n",
       " '간만에 쇼핑 중',\n",
       " '간만에 휴식 중',\n",
       " '간식 뭐 먹을까',\n",
       " '간식 추천',\n",
       " '간장치킨 시켜야지',\n",
       " '간접흡연 싫어',\n",
       " '갈까 말까 고민 돼',\n",
       " '갈까 말까?',\n",
       " '감 말랭이 먹고 싶다.',\n",
       " '감 말랭이 먹어야지',\n",
       " '감기 같애',\n",
       " '감기 걸린 것 같아',\n",
       " '감기 기운이 있어',\n",
       " '감기 들 거 같애',\n",
       " '감기가 오려나',\n",
       " '감기약이 없어',\n",
       " '감기인거 같애',\n",
       " '감미로운 목소리 좋아',\n",
       " '감정이 쓰레기통처럼 엉망진창이야',\n",
       " '감정컨트롤을 못하겠어',\n",
       " '감정컨트롤이 안돼',\n",
       " '감히 나를 무시하는 애가 있어',\n",
       " '갑자기 나쁜 생각이 막 들더라',\n",
       " '갑자기 눈물 나',\n",
       " '갑자기 물어봐서 당황했어',\n",
       " '갑자기 불편한 사이가 된 거 같아',\n",
       " '강렬한 첫인상 남겨야 하는데',\n",
       " '강아지 키우고 싶어',\n",
       " '강아지 키우고 싶은데 역시 안돼겠지',\n",
       " '강아지 키울 수 있을까',\n",
       " '강아지 키울까',\n",
       " '강원도 가서 살까?',\n",
       " '같이 게임하자고 해도 되나?',\n",
       " '같이 놀러갈 친구가 없어',\n",
       " '같이 먹었는데 나만 살찐 거 같아',\n",
       " '같이 수영장 가기로 했어',\n",
       " '같이 있으면 힘든데 붙잡고 싶어',\n",
       " '같이 피씨방 가자고 해볼까?',\n",
       " '같이 할 수 있는 취미 생활 뭐 있을까',\n",
       " '개강룩 입어볼까',\n",
       " '개강옷 예쁘게 입어 볼까',\n",
       " '개강이다',\n",
       " '개강이라니',\n",
       " '개같은 상황',\n",
       " '개같이 되버렸어.',\n",
       " '개기름 꼈어',\n",
       " '개념도 놓고 옴',\n",
       " '개념이 없어',\n",
       " '개당황',\n",
       " '개당황했잖아 갑자기 물어 봐서',\n",
       " '개인적인 업무까지 다 시켜',\n",
       " '개인적인 일도 다 시켜',\n",
       " '개졸려',\n",
       " '개좋아',\n",
       " '개학하니까 좋다',\n",
       " '걔 너무 싫다',\n",
       " '걔는 누굴 닮아서 그런거니?',\n",
       " '걔랑 같은 반 됐으면 좋겠다',\n",
       " '거지 같이 일해 놓고 갔어',\n",
       " '거지됐어',\n",
       " '거짓말 했어',\n",
       " '거짓말을 나도 모르게 자꾸 해',\n",
       " '거짓말을 하게 돼',\n",
       " '거짓말이 거짓말을 낳아',\n",
       " '걱정 없이 살고파',\n",
       " '걱정 좀 없이 살고 싶다.',\n",
       " '건강 관리',\n",
       " '건강 빨리 회복해야지',\n",
       " '건강검진 왔어',\n",
       " '건강검진하러 옴',\n",
       " '건강이 최고',\n",
       " '건강이 최고인 것 같아',\n",
       " '건강하게 다이어트 하는 방법',\n",
       " '건강한 다이어트법',\n",
       " '건너건너 아는 사람인데 연락해도 될까?',\n",
       " '건물주 되고싶어',\n",
       " '건물주가 짱인데',\n",
       " '건방져',\n",
       " '건조기 살까봐',\n",
       " '건조하네',\n",
       " '걸레질도 해야 돼',\n",
       " '걸어 가고 있는데 깜깜해서 무서워',\n",
       " '겁난다',\n",
       " '게으른 동료가 있어',\n",
       " '게임 같이 하자고 할까?',\n",
       " '게임 때문에 시간 다갔어',\n",
       " '게임 때문에 폰이 점점 느려지는듯',\n",
       " '게임 재미있어.',\n",
       " '게임 지겨워',\n",
       " '게임도 이제 재미없어',\n",
       " '게임하고 싶어',\n",
       " '게임하다 시간 다갔어',\n",
       " '겨울 지나 봄이야',\n",
       " '겨울에는 온천이지!',\n",
       " '겨울이 가고 봄이 올거야',\n",
       " '격려 좀 해줘',\n",
       " '격려가 필요해.',\n",
       " '견과류 챙겨 먹어야지.',\n",
       " '결국 이런 운명이라니 슬프다',\n",
       " '결정 못하겠어.',\n",
       " '결정은 빠르면 빠를 수록 좋겠지?',\n",
       " '결정은 빠를수록 좋겠지?',\n",
       " '결정을 못 내리겠어. 어떻해',\n",
       " '결정적인 물증이 없어',\n",
       " '결혼 했는데.',\n",
       " '결혼 했어',\n",
       " '결혼도 다 돈이다.',\n",
       " '결혼식 가기 귀찮아',\n",
       " '결혼식 또 가야돼',\n",
       " '결혼식때 하객이 없을 까봐 걱정돼',\n",
       " '결혼식이 너무 많아',\n",
       " '결혼이나 하지 왜 자꾸 나한테 화 내냐구!',\n",
       " '결혼준비 돈 많이 들겠지',\n",
       " '결혼준비하는데 돈 얼마나 드나',\n",
       " '결혼하는데 돈 많이 드네',\n",
       " '결혼하는데 돈 얼마나 들까',\n",
       " '결혼하면 좋아?',\n",
       " '결혼하면 좋을까',\n",
       " '결혼하면 행복할까?',\n",
       " '결혼하면 행복해?',\n",
       " '결혼하면 행복해질까?',\n",
       " '결혼할까',\n",
       " '결혼해도 되나',\n",
       " '결혼해도 될까',\n",
       " '결혼해야 하나',\n",
       " '경쟁이 너무 치열해',\n",
       " '계속 공부해도 될까',\n",
       " '계속 도전하는 거 귀찮아',\n",
       " '계속 방학이면 좋을텐데',\n",
       " '계속 보고 싶어',\n",
       " '계속 보고 싶으면 어떡해?',\n",
       " '계속 속이 진짜 안 좋아',\n",
       " '계속 엇갈리는 느낌',\n",
       " '계속 학생하고 싶어',\n",
       " '계속 한숨만 나와',\n",
       " '고3은 공부만 해야겠지.',\n",
       " '고3이니까 공부해야겠지',\n",
       " '고구마 다이어트 해야지',\n",
       " '고구마만 먹고 다이어트 해야지',\n",
       " '고기 구워 먹고 싶다.',\n",
       " '고기 먹고 싶어',\n",
       " '고데기 망했어',\n",
       " '고데기 했는데 망했어',\n",
       " '고독한 밤',\n",
       " '고마운 사람들이 많아',\n",
       " '고무신 거꾸로 신으면 어쩌지',\n",
       " '고민 있어',\n",
       " '고민 좀 들어줄래',\n",
       " '고백하고 후회하면 어떡하지',\n",
       " '고시원 너무 답답해',\n",
       " '고시원 답답해',\n",
       " '고시원에서 나가고 싶어',\n",
       " '고시원에서 탈출하고 싶어',\n",
       " '고양이 동영상 보는 중',\n",
       " '고양이 키우고 싶어',\n",
       " '고양이 키우고 싶어',\n",
       " '고의는 아닌데 실수를 한 거 같아',\n",
       " '고집 센 사람',\n",
       " '고집하고는',\n",
       " '골프 못 치는데',\n",
       " '골프 배워야 돼',\n",
       " '골프 어려워',\n",
       " '골프치러 가야돼',\n",
       " '곱창 먹고 싶어.',\n",
       " '곱창 생각나',\n",
       " '공무원 괜찮겠지',\n",
       " '공무원 되고 싶다',\n",
       " '공무원 되면 좋겠다',\n",
       " '공무원 시험 공부 힘들다',\n",
       " '공무원 시험 죽을 거 같아',\n",
       " '공무원 시험 힘들어ㅠㅠ',\n",
       " '공무원 준비할까',\n",
       " '공무원이 좋지?',\n",
       " '공복이라 신경이 예민해져',\n",
       " '공복이라 예민해',\n",
       " '공복이면 예민함?',\n",
       " '공부 계속해도 될까',\n",
       " '공부 꼭 해야 할까',\n",
       " '공부 때려치워야 하나',\n",
       " '공부 시작해도 될까',\n",
       " '공부 왜 해야 돼?',\n",
       " '공부 잘 안돼',\n",
       " '공부 잘하고 싶어',\n",
       " '공부 좀 더 할 걸',\n",
       " '공부 하기 싫다',\n",
       " '공부는 내 체질이 아닌 것 같아',\n",
       " '공부로 먹고 살 수 있을까',\n",
       " '공부방법이 잘못된걸까?',\n",
       " '공부하기 싫어',\n",
       " '공부하기 싫은 날',\n",
       " '공부하는 낙이 없어',\n",
       " '공부하는 이유?',\n",
       " '공부하는 이유가 없어',\n",
       " '공시 준비 힘들어',\n",
       " '공시 준비 힘들어',\n",
       " '공시 준비중',\n",
       " '공시 준비하는데 힘들다',\n",
       " '공시생이야',\n",
       " '공연 보고 싶어',\n",
       " '공연 보러 가고 싶어',\n",
       " '공책 필기 나만 힘들어?',\n",
       " '공황장애 생겼어.',\n",
       " '공황장애 있어',\n",
       " '공휴일에는 집이 최고',\n",
       " '공휴일에는 집콕',\n",
       " '과거는 잊고 앞으로 나아 가야지',\n",
       " '과거는 중요하지 않아',\n",
       " '과식해서 소화가 안돼',\n",
       " '과식했나 봐',\n",
       " '과식했다',\n",
       " '과외비 부담되겠지?',\n",
       " '과외비 비싸?',\n",
       " '과일 먹고 자야지',\n",
       " '과일 먹어야지.',\n",
       " '과일 안 먹게 돼',\n",
       " '과일 잘 안 먹게 돼',\n",
       " '과일 챙겨 먹어야지',\n",
       " '관계가 계속 애매하다.',\n",
       " '관심 끄라고 하고 싶다.',\n",
       " '관심 좀 안 가졌으면',\n",
       " '관절염 같애',\n",
       " '관절염인가',\n",
       " '광고가 안 끝나',\n",
       " '괜찮아지고 있어',\n",
       " '괜찮은 사람인데 사귀긴 싫어',\n",
       " '괜히 건들지 말라고',\n",
       " '괜히 기다렸어',\n",
       " '괜히 농담해서 망했다',\n",
       " '괜히 아까운 시간 버렸다',\n",
       " '괜히 창피해',\n",
       " '괴물이 되어 가는 느낌이 들어',\n",
       " '교보문고 왔어',\n",
       " '교양 수업 재밌어',\n",
       " '교양수업 시간에 마음에 드는 애 있어',\n",
       " '교양수업 은근 재미져',\n",
       " '교양수업에서 마음에 드는 애 있어',\n",
       " '교양수업이 재미있어',\n",
       " '교양이 전공보다 재미있어',\n",
       " '교직이수 가능할까',\n",
       " '교통사고 났었어.',\n",
       " '교통사고 당했어',\n",
       " '교회 가기 싫어',\n",
       " '교회 갔다 만났어',\n",
       " '교회에서 만났어',\n",
       " '구박하면서 엄청 일 시켜',\n",
       " '군대 갔다 올 때까지 기다릴 수 있을까',\n",
       " '군대 기다려 주려고',\n",
       " '군대 기다려도 될까',\n",
       " '군대 기다리면 부담스러워할까',\n",
       " '군대 기다릴 수 있을까',\n",
       " '군대 언제 끝나나',\n",
       " '군대 전역 기다려',\n",
       " '굿모닝',\n",
       " '궁금하면 오백원',\n",
       " '궁금하지?',\n",
       " '궁금해',\n",
       " '궁금해 알려줘',\n",
       " '귀 아파',\n",
       " '귀가 가려워',\n",
       " '귀가 간지러',\n",
       " '귀가 윙윙거려',\n",
       " '귀농 어때?',\n",
       " '그 사람이 나 안 좋아하는 거 같아',\n",
       " '그 사람이 나 좋아해줬으면 좋겠다',\n",
       " '그 사람이 행복했으면 좋겠다',\n",
       " '그 시절엔 다 그랬지',\n",
       " '그냥 고백할걸',\n",
       " '그냥 공무원이 좋을 듯',\n",
       " '그냥 내버려 둬 주었으면',\n",
       " '그냥 선 볼까?',\n",
       " '그냥 쉬고 싶다',\n",
       " '그냥 씹어야겠다.',\n",
       " '그냥 이렇게 살고 싶어',\n",
       " '그냥 자는 거 아니지?',\n",
       " '그냥 잘못했다고 하면 될거 같은데 자꾸 변명해',\n",
       " '그냥 택시 타야지.',\n",
       " '그냥 할까?',\n",
       " '그냥 혼자 밥이나 먹어야지',\n",
       " '그냥 혼자 있는게 좋아',\n",
       " '그동안 잘 지냈나요?',\n",
       " '그땐 그랬지',\n",
       " '그래 그러자',\n",
       " '그래 이제 결정했어',\n",
       " '그래도 좀 기대했는데',\n",
       " '그런 말을 왜 하지',\n",
       " '그런 사람인가보다 해야하나봐',\n",
       " '그런 사람인갑다 해야지',\n",
       " '그런 친구 아니었는데 너무 귀찮게 하네',\n",
       " '그렇게 갈 거면서',\n",
       " '그렇게 오래 살았는데도 이해를 못하겠어',\n",
       " '그렇게 할래',\n",
       " '그림 잘 그리고 싶다',\n",
       " '그림 좀 잘 그렸으면 좋겠다',\n",
       " '그만 두고 나오고 싶어',\n",
       " '그만 먹어야 하는데',\n",
       " '그만 살고싶어',\n",
       " '그저 그런 하루',\n",
       " '근사한 곳 알아 냈어',\n",
       " '근육 있으면 멋있을텐데',\n",
       " '금값 알아?',\n",
       " '금값 어때',\n",
       " '금사빠인가',\n",
       " '금수저 물고 태어나면 좋겠지?',\n",
       " '금수저로 태어났으면',\n",
       " '금수저로 태어났으면 좋았을텐데',\n",
       " '금연이 쉽지 않아',\n",
       " '기 빨렸어',\n",
       " '기념일 다 챙기는거 귀찮아',\n",
       " '기념일 또 까먹었어',\n",
       " '기념일 못챙겼어',\n",
       " '기념일 챙기기 귀찮아',\n",
       " '기능 좀 알려줘봐봐',\n",
       " '기다리는 것도 지쳐',\n",
       " '기다리라고 말 못하겠어',\n",
       " '기다림이 습관이 됐나봐',\n",
       " '기대가 무너졌어',\n",
       " '기대가 부담스러운데 떨쳐낼 수 있는 방법 있을까?',\n",
       " '기대하고 있었는데',\n",
       " '기대하지 말걸',\n",
       " '기대했는데',\n",
       " '기댈 수 있는 사람',\n",
       " '기력이 없어',\n",
       " '기름값 올랐어.',\n",
       " '기본이 뭔지도 모르는 것 같아.',\n",
       " '기본이 안 되어 있어',\n",
       " '기부 좀 했어요',\n",
       " '기부했어',\n",
       " '기분 꿀꿀해',\n",
       " '기분 나쁜 농담을 계속하고 있어',\n",
       " '기분 울적해서 좀 걷고 있어',\n",
       " '기분 전환 하고 싶어',\n",
       " '기분 전환이 필요해',\n",
       " '기분이 그지 같아',\n",
       " '기분이 더러워',\n",
       " '기분이 묘해',\n",
       " '기분이 이상해',\n",
       " '기숙사 괜찮을까',\n",
       " '기숙사 떨어졌어',\n",
       " '기숙사 사는거 어떨까?',\n",
       " '기숙사 살면 불편해?',\n",
       " '기숙사 안됐어',\n",
       " '기술 배울까',\n",
       " '기차 타고 여행 가고 싶어',\n",
       " '기차여행 가고 싶어',\n",
       " '기침도 못하겠어',\n",
       " '기침도 편하게 못해',\n",
       " '기프트콘 받았어!',\n",
       " '기프트콘 선물 괜찮을까?',\n",
       " '기프트콘 선물해볼까?',\n",
       " '기프트콘 주면 좋아할까?',\n",
       " '기프트콘으로 선물 받았어',\n",
       " '기프트콘으로 선물 해야겠다',\n",
       " '기회를 놓쳤어',\n",
       " '기회를 못 잡았어',\n",
       " '기획사니까 당연히 예쁜 애들 많겠지',\n",
       " '기획사에 예쁜 애들 많겠지',\n",
       " '긴 머리 관리 어렵다.',\n",
       " '긴 머리 관리하는 거 힘들다',\n",
       " '긴 시간이 걸렸지만 괜찮아.',\n",
       " '긴장 푸는 법 알려줘',\n",
       " '긴장돼',\n",
       " '긴장돼서 땀나네',\n",
       " '길거리에서 연락처 물어보면 줘도 되나',\n",
       " '길에서 담배 피우는 사람 싫어',\n",
       " '길에서 번호 따였어',\n",
       " '길에서 전번 물어보면 줘도 되나',\n",
       " '길에서 헌팅 당했어',\n",
       " '길은 멀고 해는 진다',\n",
       " '길이 미끄러워서 미끄러질뻔했어',\n",
       " '길이 안보여',\n",
       " '길이 얼어서 미끄러질뻔했어',\n",
       " '길이 얼었어',\n",
       " '김떡순 먹고 싶어.',\n",
       " '김치도 없네',\n",
       " '김치볶음밥 먹어야지',\n",
       " '김치볶음밥이나 만들어 먹어야지',\n",
       " '김치찌개 먹고 싶어',\n",
       " '까아 오빠들 컴백한다',\n",
       " '깜깜한데 전기 안들어오네',\n",
       " '깡 마른 거 같아',\n",
       " '꼴 사나워질 것 같은데',\n",
       " '꽃 받고 싶다',\n",
       " '꽃 사고 싶어',\n",
       " '꽃 살까?',\n",
       " '꽃 선물 좋아할까',\n",
       " '꽃 선물해 볼까',\n",
       " '꽃 예쁘게 말렸어',\n",
       " '꽃게탕 맛있다.',\n",
       " '꽃게탕 진짜 밥도둑',\n",
       " '꽃꽂이 배우는 중',\n",
       " '꽃꽂이 배우니까 좋다',\n",
       " '꽃놀이 가고 싶어',\n",
       " '꽃다발 말려봐야지',\n",
       " '꽃다발 말리면 에쁘겠지.',\n",
       " '꽃다발 받았어',\n",
       " '꽃다발 샀어',\n",
       " '꽃다발 선물 괜찮지?',\n",
       " '꽃다발 선물 받았어',\n",
       " '꽃다발 선물 어때?',\n",
       " '꽃다발 준비했어',\n",
       " '꽃바구니 선물이랑 과일 바구니 선물 뭐가 좋아?',\n",
       " '꽃바구니가 좋을까 과일바구니까 좋을까',\n",
       " '꽃선물 받고 어',\n",
       " '꿀잼',\n",
       " '꿈은 많은데',\n",
       " '꿈이 너무 많아',\n",
       " '꿈이 너무 무서웠어',\n",
       " '꿈이 다양해',\n",
       " '꿈이 두 개야',\n",
       " '꿈이 없어',\n",
       " '꿈이 이루어질까?',\n",
       " '꿈이 자꾸 바뀌어',\n",
       " '꿈이 현실이었으면',\n",
       " '끝나니까 허무하다',\n",
       " '끝나면 좋을 줄 알았는데.',\n",
       " '낌새가 이상하더니 딱 걸렸어',\n",
       " '낌새가 있더니 딱 걸렸어',\n",
       " '나 감정쓰레기통이었나봐',\n",
       " '나 갖고 장난친건가',\n",
       " '나 같은 사람은 동물 키우면 안되겠지',\n",
       " '나 같이 예쁜 애를 왜 갈구지',\n",
       " '나 거짓말 못하겠어',\n",
       " '나 결정 잘 한거지?',\n",
       " '나 결정했어',\n",
       " '나 괜찮지 않니',\n",
       " '나 교직이수할 수 있을까?',\n",
       " '나 그동안 뭐한거니',\n",
       " '나 그지임',\n",
       " '나 내일 기숙사 가야돼',\n",
       " '나 내장비만이래',\n",
       " '나 너무 못 생겼어',\n",
       " '나 너무 소심해',\n",
       " '나 노트북 사줘',\n",
       " '나 놀려먹기 쉬운가?',\n",
       " '나 누구게?',\n",
       " '나 누락됐나봐',\n",
       " '나 다른 거 할까',\n",
       " '나 대충한 거 아닌데',\n",
       " '나 뒷담화하는 애 어떻게 할까?',\n",
       " '나 뒷담화하는 애 있다는데 어떻게 하지?',\n",
       " '나 많이 기대했는데',\n",
       " '나 말 실수한 거 같아.',\n",
       " '나 맨날 속는 거 같아',\n",
       " '나 머리 나쁜 듯',\n",
       " '나 머리가 나뿐 것 같아',\n",
       " '나 먼저 잘게',\n",
       " '나 모르는게 왜 이렇게 많지',\n",
       " '나 몰래 사귀는 거 같애',\n",
       " '나 무시 당한 거 같아',\n",
       " '나 무시하는 거 같아',\n",
       " '나 무시하는 사람 어떻게 해?',\n",
       " '나 무시하는 사람 짜증나',\n",
       " '나 문제가 많은거 같아',\n",
       " '나 뭐하는 거지',\n",
       " '나 미팅한다!',\n",
       " '나 바뀌고 싶어',\n",
       " '나 바본인가 봄',\n",
       " '나 백수야',\n",
       " '나 버림 받은 거 같아',\n",
       " '나 보이스피싱 당한 거 같은데 어떡해?',\n",
       " '나 비만이야',\n",
       " '나 사랑하니?',\n",
       " '나 상 받는대!',\n",
       " '나 새 옷 샀다',\n",
       " '나 서류에서 광탈했어',\n",
       " '나 소개팅한다!',\n",
       " '나 속은 거 같아',\n",
       " '나 속은듯',\n",
       " '나 수학여행 간다',\n",
       " '나 스마트폰 중독인가봐',\n",
       " '나 승진했어',\n",
       " '나 실수한건가',\n",
       " '나 실수했나',\n",
       " '나 아재인가',\n",
       " '나 아직 어른 아닌 거 같아',\n",
       " '나 아직도 애 같아.',\n",
       " '나 어때?',\n",
       " '나 여기서 뭐하는 거지',\n",
       " '나 연기 너무 못해 거짓말 못하겠어',\n",
       " '나 열심히 할거야',\n",
       " '나 오늘 개불쌍',\n",
       " '나 오늘 따라 잘생겨 보이네',\n",
       " '나 오늘 상 받았지롱',\n",
       " '나 완전 계탔어!',\n",
       " '나 왕따야',\n",
       " '나 왕따인거 같아',\n",
       " '나 왜 멍청해',\n",
       " '나 왜 이러지?',\n",
       " '나 왜케 못 생겼지',\n",
       " '나 요즘 정신 놓고 살고 있는 거 같아',\n",
       " '나 욕 먹는 거 같아',\n",
       " '나 웃겨 봐',\n",
       " '나 은근 무시하는 애 있어',\n",
       " '나 이상한가',\n",
       " '나 이상해?',\n",
       " '나 이제 졸업해',\n",
       " '나 인정받고 싶어',\n",
       " '나 잘 살 수 있겠지',\n",
       " '나 잘생겼지?',\n",
       " '나 잘하고 있는 건지 모르겠어',\n",
       " '나 잘하고 있는 걸까?',\n",
       " '나 잘하는 게 없어',\n",
       " '나 잘하는게 없는거같아',\n",
       " '나 잘할 수 있을까',\n",
       " '나 점점 괴물이 되고 있어',\n",
       " '나 정신차리게 말해줘',\n",
       " '나 좀 건들지 마',\n",
       " '나 좀 건들지 말라고 해',\n",
       " '나 좀 내버려 두면 좋겠어',\n",
       " '나 좀 내버려 뒀으면',\n",
       " '나 좀 안 건들였으면 좋겠어',\n",
       " '나 좀 좋아해줬으면',\n",
       " '나 좀 쩌는 듯',\n",
       " '나 좀 칭찬해줘',\n",
       " '나 좋아하게 만들고 싶다',\n",
       " '나 좋아하는 것 같아',\n",
       " '나 좋아해주는 사람 있겠지?',\n",
       " '나 주름살 있나?',\n",
       " '나 죽을 뻔함',\n",
       " '나 짤릴 거 같아',\n",
       " '나 쫌 불쌍한 거 같아',\n",
       " '나 챙겨줄 사람이 필요해',\n",
       " '나 천재 같아',\n",
       " '나 천재임',\n",
       " '나 축구는 진짜 잘해',\n",
       " '나 친구들한테 인정받고 싶어',\n",
       " '나 폭식증인듯',\n",
       " '나 폰 중독인 거 같애',\n",
       " '나 폰겜 너무 많이해',\n",
       " '나 폰겜했더니 몇 시간 갔어',\n",
       " '나 할 수 있어',\n",
       " '나 함부로 말하는 거 고치고 싶어',\n",
       " '나 혼자 야근해',\n",
       " '나 혼자 여행 왔는데 괜찮네',\n",
       " '나 혼자서 축구 본다',\n",
       " '나 화장을 너무 못해',\n",
       " '나 화장이 잘 안돼',\n",
       " '나 회사에서 인정받고 싶어',\n",
       " '나가기도 귀찮아',\n",
       " '나는 그냥저냥 사는 거 같아',\n",
       " '나는 기분 나쁜데 농담이라고 계속해',\n",
       " '나는 나약한 존재',\n",
       " '나는 누구인가',\n",
       " '나는 모자란 사람인 거 같아',\n",
       " '나는 뭐든 할 수 있다.',\n",
       " '나는 뭘 잘할까',\n",
       " '나는 왜 이 모양일까',\n",
       " '나는 왜 이렇게 태어났을까?',\n",
       " '나는 왜 태어났을까',\n",
       " '나는 잘 할줄 아는 게 없는 것 같아',\n",
       " '나는 좋아하는 게 뭘까',\n",
       " '나는 좋은데 ….',\n",
       " '나는 친구가 없어',\n",
       " '나는 친구라고 믿었는데',\n",
       " '나도 괜찮은 사람인데',\n",
       " '나도 대우 받고 싶다고',\n",
       " '나도 비키니 입고 싶다',\n",
       " '나도 상 받고 싶다',\n",
       " '나도 약초 캐볼까?',\n",
       " '나도 월급 필요해',\n",
       " '나도 위로 받고 싶다',\n",
       " '나도 이벤트가 되다니!',\n",
       " '나도 이제 아재인가',\n",
       " '나도 중국 진출해볼까?',\n",
       " '나도 집 사고 싶어',\n",
       " '나도 커플룩 입고 싶다',\n",
       " '나두 잘할거야',\n",
       " '나들이를 가볼까',\n",
       " '나란 놈',\n",
       " '나랑 놀아줘',\n",
       " '나랑 놀자',\n",
       " '나랑 상관 없는 이야기들',\n",
       " '나랑 있는게 힘들었나봐',\n",
       " '나른하다',\n",
       " '나를 기다려줬으면 좋겠다',\n",
       " '나를 너무 오래 기다리게했어',\n",
       " '나를 너무 함부로 대해',\n",
       " '나를 미소짓게 만든 너',\n",
       " '나를 바꿀 수 있는 건 뭐가 있을까',\n",
       " '나를 친구로 생각 안했나봐',\n",
       " '나를 호구로 아는 사람 어떡해?',\n",
       " '나를 힘들게 하는 사람인데 붙잡고 싶어',\n",
       " '나만 갈궈',\n",
       " '나만 기다렸나봐',\n",
       " '나만 꿈 없이 사는 거 같아',\n",
       " '나만 남친 없어',\n",
       " '나만 뒤처지는 느낌이야',\n",
       " '나만 반친구 없어',\n",
       " '나만 빼고 행복해보여',\n",
       " '나만 설레나',\n",
       " '나만 설레는 거야',\n",
       " '나만 솔로야',\n",
       " '나만 애기봐',\n",
       " '나만 야근해',\n",
       " '나만 우스워질거 같아',\n",
       " '나만 이상한 사람이래',\n",
       " '나만 이상해졌어',\n",
       " '나만 일시켜서 짜증폭발',\n",
       " '나만 제자리걸음이야',\n",
       " '나만 제자리인듯',\n",
       " '나만 진급 못했어',\n",
       " '나만 친구라고 생각한건가',\n",
       " '나만 친구로 생각했나봐',\n",
       " '나만 힘든 거 아니지?',\n",
       " '나만의 시간이 필요한 것 같아',\n",
       " '나만의 시간이 필요해',\n",
       " '나빼고 다 행복한 거 같아',\n",
       " '나쁜 꿈 꿨어',\n",
       " '나이 때문에 무시 받았어',\n",
       " '나이 어리다고 무시해',\n",
       " '나이가 많은데 취직이 될까',\n",
       " '나이도 있으니 영양제 좀 챙겨볼까',\n",
       " '나이들면서 눈물이 많아졌어',\n",
       " '나이먹으니까 주름살 생겨',\n",
       " '나중에 뭐하고 먹고 사냐',\n",
       " '나중에 뭐할까 고민이야',\n",
       " '나중에 창업해야 겠지',\n",
       " '나한테 감추는 게 하나도 없었으면',\n",
       " '나한테 거짓말 좀 안 했으면',\n",
       " '나한테 냄새 나면 어쩌지?',\n",
       " '나한테 냄새 날까?',\n",
       " '나한테 너무 많은 걸 바라는 듯',\n",
       " '나한테 문제가 많아',\n",
       " '나한테 상의 좀 하지',\n",
       " '나한테 상의하면 좋을텐데',\n",
       " '나한테 이상한 냄새 나나?',\n",
       " '나한테 할 말 있대 뭘까?',\n",
       " '나한테 행운 좀 왔으면 좋겠어',\n",
       " '나한테만 예의 차리래',\n",
       " '나한테만 왜 이런 일이 일어날까',\n",
       " '나한테만은 완전 솔직했으면',\n",
       " '낙엽 밟는 소리 좋다',\n",
       " '낙엽밟는 소리',\n",
       " '낚시 안 해봤는데',\n",
       " '낚시 안 해봤는데 재미있어 보인다',\n",
       " '낚시 재밌을까',\n",
       " '낚시 좋아하는 남자 어때?',\n",
       " '낚시는 무슨 재미?',\n",
       " '난 동물 못키울거 같아',\n",
       " '난 많이 노력한 거 같은데',\n",
       " '난 쓰레기야',\n",
       " '난 왜 예쁘게 말을 못할까',\n",
       " '난 왜 이모양일까',\n",
       " '난 정말 안되겠다',\n",
       " '난 진짜 쓰레기야',\n",
       " '난 천재다',\n",
       " '난방비 비싼데 추워',\n",
       " '난방이 안돼',\n",
       " '난방이 안돼나 추워',\n",
       " '날 몇시간동안이나 기다리게했어',\n",
       " '날씨 건조한 거 같애',\n",
       " '날씨 왜 이렇게 춥냐',\n",
       " '날씨 좀 풀린거 같아',\n",
       " '날씨 좋은데',\n",
       " '날씨 죽인다',\n",
       " '날씨 짱 좋아',\n",
       " '날씨 풀렸다',\n",
       " '날씨가 너무 눅눅해',\n",
       " '날씨가 너무 추워',\n",
       " '날씨가 북극같아',\n",
       " '날씨가 진짜 덥다',\n",
       " '날아 가고 싶어',\n",
       " '남동생한테 자꾸 화내게 되네',\n",
       " '남들에게 인정받으려면 어떻게 해야 돼?',\n",
       " '남들이 날 욕하는 거 같아',\n",
       " '남들이 다 손가락질 하는 거 같아',\n",
       " '남은 휴가가 없어',\n",
       " '남의 눈을 너무 신경써',\n",
       " '남의 일 도와줘야 할까',\n",
       " '남의 차 긁었어 내 돈',\n",
       " '남이 걷지 않는 길을 가려고 해',\n",
       " '남자 보통 어디서 만나',\n",
       " '남자 어디서 만나',\n",
       " '남자 친구가 바래다 줬어',\n",
       " '남자 화장하는 거 어때',\n",
       " '남자가 낚시를 너무 좋아해',\n",
       " '남자가 화장하는 거 어떻게 생각해',\n",
       " '남자면 편할 것 같아',\n",
       " '남자였으면 좋겠어',\n",
       " '남자인지 여자인지 알려줘',\n",
       " '남자친구 교회 데려가고 싶어',\n",
       " '남자친구 또 운동 갔어',\n",
       " '남자친구 생일인데 뭘 줄까',\n",
       " '남자친구 승진 선물로 뭐가 좋을까?',\n",
       " '남자친구 오늘 따라 훈훈해 보인다',\n",
       " '남자친구 오늘 좀 질린다.',\n",
       " '남자친구가 나 안 믿어줘',\n",
       " '남자친구가 너무 바빠',\n",
       " '남자친구가 너무 운동만 해',\n",
       " '남자친구가 너무 잘생겼어',\n",
       " '남자친구가 데려다줬어',\n",
       " '남자친구가 맞춤법을 너무 많이 틀려',\n",
       " '남자친구가 사업 시작한대',\n",
       " '남자친구가 사업한대',\n",
       " '남자친구가 사진 실력 꽝',\n",
       " '남자친구가 사진을 너무 못 찍어',\n",
       " '남자친구가 안놀아 줘',\n",
       " '남자친구가 애교가 많아',\n",
       " '남자친구가 욕함',\n",
       " '남자친구가 의심해',\n",
       " '남자친구가 이벤트 해 주면 좋겠다.',\n",
       " '남자친구가 이벤트를 잘 안해줘',\n",
       " '남자친구가 입이 험해',\n",
       " '남자친구가 자꾸 잔소리해',\n",
       " '남자친구가 잔소리가 심해',\n",
       " '남자친구가 전화를 잘 안해',\n",
       " '남자친구가 전화하는 걸 안 좋아해',\n",
       " '남자친구가 홧김에 욕함',\n",
       " '남자친구는 어디서 만나',\n",
       " '남자친구랑 봉사활동 해보려고',\n",
       " '남자친구랑 종교 문제로 다툼',\n",
       " '남자친구랑 종교가 달라',\n",
       " '남자친구한테 질린 거 같아',\n",
       " '남친 SNS에 내 사진 없어',\n",
       " '남친 때문에 살찐 듯',\n",
       " '남친 보여줄까',\n",
       " '남친 생일선물 뭘 주면 좋을까',\n",
       " '남친 승진 선물 추천',\n",
       " '남친 어디서 만나',\n",
       " '남친 프로필에 내 사진 왜 안올릴까',\n",
       " '남친 프사에 내 사진 없어',\n",
       " '남친이 SNS에 내 사진에 안 올려',\n",
       " '남친이 입이 험해',\n",
       " '남친한테 교회 가자고 하고 싶어',\n",
       " '남편이 나 안 도와줘',\n",
       " '남편이 나보다 집안일 더 잘해',\n",
       " '남편이 맨날 늦게 들어와',\n",
       " '남편이 미워',\n",
       " '남편이 아기를 안 돌봐줘.',\n",
       " '남편이 왜 애키우는거 안 도와줄까',\n",
       " '남편이 육아를 안해',\n",
       " '남편이 육아에 무신경해',\n",
       " '남편이 집안일 안 도와줘.',\n",
       " '남편이 집안일 안 해',\n",
       " '남편이 집안일을 너무 잘해',\n",
       " '남편이 짜증나게해',\n",
       " '남편이 하나도 안 도와줘',\n",
       " '남편이 회식이라고 안와',\n",
       " '남편이 회식하면 늦게 들어와',\n",
       " '낭만이 사라진 것 같아',\n",
       " '낭만이 없어',\n",
       " '낭만이라고는 없어가지구',\n",
       " '내 남자친구 보고 싶어?',\n",
       " '내 남자친구 아이돌이면 좋겠다.',\n",
       " '내 능력이 너무 모자라',\n",
       " '내 마음을 알아줬으면',\n",
       " '내 마음을 좀 알아 달라고',\n",
       " '내 몸이 여러 개 였으면 좋겠다',\n",
       " '내 문제는 뭘까',\n",
       " '내 문제점이 뭘까',\n",
       " '내 배우자는 어디 있을까',\n",
       " '내 배우자도 어디 있을까?',\n",
       " '내 사수 너무 깐깐해',\n",
       " '내 생각대로 살거야',\n",
       " '내 생각이랑 다른 사람 생각이 진짜 다르다는 걸 느껴',\n",
       " '내 성격 너무 소심해',\n",
       " '내 스타일 아니던데',\n",
       " '내 스타일 아니야',\n",
       " '내 실력 좀 쩌는 듯',\n",
       " '내 얼굴이 읽히나',\n",
       " '내 여자친구 아이돌이야',\n",
       " '내 외모 맘에 안들어',\n",
       " '내 월급만 안 올라',\n",
       " '내 의견 좀 존중해 줬으면',\n",
       " '내 의견을 존중해줬으면',\n",
       " '내 의지는 상관없나봐',\n",
       " '내 의지로 안되는 일인가봐',\n",
       " '내 이름이 없어',\n",
       " '내 인생 답 없어',\n",
       " '내 인생은 가시밭길 같아',\n",
       " '내 인생의 주인공은 나야',\n",
       " '내 일 아닌데 해야 돼?',\n",
       " '내 자존감',\n",
       " '내 잘못이 뭔지 모르겠어',\n",
       " '내 잘못인 거 같은데 말을 못하겠어',\n",
       " '내 잘못인 거 같은데 어떻게 털어놓지',\n",
       " '내 주제를 모르고 덤빈건가',\n",
       " '내 지인한테 내 험담했대',\n",
       " '내 집이 생겼어',\n",
       " '내 짝은 어디있을까',\n",
       " '내 친구에게 내 험담을 하다니',\n",
       " '내 키 맞춰 봐',\n",
       " '내 키가 몇이게?',\n",
       " '내 편이 없는 거 같아',\n",
       " '내 편이라고는 하나도 없는 거 같아',\n",
       " '내가 그렇게 부족한가',\n",
       " '내가 그르친 거 같아',\n",
       " '내가 그사람이랑 진짜 결혼해도 될까',\n",
       " '내가 기대를 너무 많이 했나봐',\n",
       " '내가 나빴네',\n",
       " '내가 너무 방심했어',\n",
       " '내가 너무 생각없이 말했어',\n",
       " '내가 너무 쉽게 보였나?',\n",
       " '내가 너무 초라해',\n",
       " '내가 다른 무슨 말을 하겠어',\n",
       " '내가 만족을 못해',\n",
       " '내가 많이 부족한가',\n",
       " '내가 말하면 왜 비난만 할까',\n",
       " '내가 멍청한거지',\n",
       " '내가 무능력하게 느껴져',\n",
       " '내가 뭘 잘못했을까',\n",
       " '내가 뭘 좋아하는지 잘하는지 모르겠어',\n",
       " '내가 바보지',\n",
       " '내가 부족하니까 이렇게 밖에 안된거겠지.',\n",
       " '내가 불효녀야',\n",
       " '내가 불효자야',\n",
       " '내가 사랑할 자격이 있나',\n",
       " '내가 쉬워보이나?',\n",
       " '내가 쓸모없는 인간 같아',\n",
       " '내가 아무것도 아닌 사람 같아',\n",
       " '내가 왜 해야하는지 모르겠어',\n",
       " '내가 원하는 사람이 되기 어려워',\n",
       " '내가 이래뵈도 괜찮은 사람인데',\n",
       " '내가 이렇게 또 불효를 한다.',\n",
       " '내가 이상한 건가?',\n",
       " '내가 이상한 사람같아',\n",
       " '내가 이상한가?',\n",
       " '내가 잘못한 걸까',\n",
       " '내가 잘못했다는데 뭔지 안 알려줘',\n",
       " '내가 제일 문제인 듯',\n",
       " '내가 제정신이 아니다',\n",
       " '내가 좋아하는 가수 컴백한다',\n",
       " '내가 좋아하는 거 모르나',\n",
       " '내가 좋아하는 거 모르는 거 같애',\n",
       " '내가 좋아하는 사람과 나를 좋아해주는 사람',\n",
       " '내가 좋아하는 사람이 나 안 좋아하는 거 같아',\n",
       " '내가 좋아하는 사람이 나 좋아해줬으면 좋겠다',\n",
       " '내가 좋아하는 사람이 행복했으면 좋겠다',\n",
       " '내가 좋아할 자격이 있나',\n",
       " '내가 주제를 몰랐나봐',\n",
       " '내가 주제를 몰랐던 거지',\n",
       " '내가 죽어도 모를 거 같아',\n",
       " '내가 진짜 즐길 수 있을게 뭘까',\n",
       " '내가 질린대',\n",
       " '내가 참 못난거 같아',\n",
       " '내가 호구냐구',\n",
       " '내가 희생양이 됐어',\n",
       " '내가 힘든 게 많다',\n",
       " '내기해서 이겼는데 소원 뭐하지',\n",
       " '내년에는 더 행복해질려고 이렇게 힘든가봅니다',\n",
       " '내마음을 모르겠어.',\n",
       " '내사랑은 어디 있나',\n",
       " '내아파트 갖고 싶어.',\n",
       " '내일 기대하게 되네',\n",
       " '내일 기숙사 들어가',\n",
       " '내일 날씨 어때?',\n",
       " '내일 날씨 좋을까?',\n",
       " '내일 떨린다',\n",
       " '내일 만나자고 데쉬?',\n",
       " '내일 만나자고 해볼까?',\n",
       " '내일 모의고사 본다',\n",
       " '내일 모의평가다',\n",
       " '내일 발표 나는데 떨려',\n",
       " '내일 발표 준비 아자아자',\n",
       " '내일 발표 준비하고 있어',\n",
       " '내일 발표인데 떨려',\n",
       " '내일 비왔으면',\n",
       " '내일 소풍간다',\n",
       " '내일 수학여행가!',\n",
       " '내일 시험이야',\n",
       " '내일 약속 있는데 날씨 좋았으면',\n",
       " '내일 일찍 일어나야 돼',\n",
       " '내일 친구랑 놀까?',\n",
       " '내일 클스마스 이브네.',\n",
       " '내일 하루 종일 바빠',\n",
       " '내일은 기다리던 소풍 간다',\n",
       " '내일은 비왔으면 좋겠다.',\n",
       " '내일은 친구들랑 놀까?',\n",
       " '내일이 기대돼',\n",
       " '내일이면 크리스마스 이브네.',\n",
       " '내장 비만',\n",
       " '낼 데이트하기로했는데 날씨 좋았으면',\n",
       " '낼 바쁘넹',\n",
       " '냄새 나면 어쩌지?',\n",
       " '냄새나면 어쩌지',\n",
       " '냄새날 것 같아 걱정이야',\n",
       " '냉면 땡긴다',\n",
       " '냉방비 너무 많이 나와',\n",
       " '냉방비 장난 아님',\n",
       " '냉장고 털어도 먹을게 없네',\n",
       " '냉장고가 텅비었어',\n",
       " '냉장고에 김치도 없네',\n",
       " '냉장고에 먹을 게 없네',\n",
       " '냉장고에 먹을 게 하나도 없네',\n",
       " '너 누구?',\n",
       " '너 누구냐',\n",
       " '너 누구니?',\n",
       " '너 때문이야',\n",
       " '너 또 뭐할 줄 알아?',\n",
       " '너 만든 사람 최소 천재',\n",
       " '너 만든 사람은 누구야?',\n",
       " '너 말 잘하니',\n",
       " '너 말 제대로 못해?',\n",
       " '너 말이 좀 이상하다',\n",
       " '너 무서워',\n",
       " '너 뭐하는 애야',\n",
       " '너 미워',\n",
       " '너 이러면 미워한다',\n",
       " '너 진짜 쓰레기야',\n",
       " '너는 못가잖아',\n",
       " '너는 뭐 억었어?',\n",
       " '너는 아무일도 없었나봐?',\n",
       " '너는 안자?',\n",
       " '너덜너덜해진 느낌이야',\n",
       " '너도 고민 있니',\n",
       " '너도 고민 있어?',\n",
       " '너도 몰랐니',\n",
       " '너도 무슨 고민 있니',\n",
       " '너도 상사 있어',\n",
       " '너무 기빨려',\n",
       " '너무 기대했나봐',\n",
       " '너무 다른 문화인 듯',\n",
       " '너무 단순한 것만 하는거 아니니.',\n",
       " '너무 더워',\n",
       " '너무 더워서 미치겠어',\n",
       " '너무 마른 거 같아',\n",
       " '너무 많은 걸 바래',\n",
       " '너무 많이 먹어서 소화시켜야 하는데 움직이기가 싫어',\n",
       " '너무 많이 먹었나봐',\n",
       " '너무 많이 먹었어',\n",
       " '너무 멋있다',\n",
       " '너무 바빠',\n",
       " '너무 배가 불러',\n",
       " '너무 불공평한거 같애',\n",
       " '너무 빨리 대답해',\n",
       " '너무 빨리 철 든 거 같아서 마음이 아파',\n",
       " '너무 빨리 철 들었어',\n",
       " '너무 뻔뻔하게 구는데',\n",
       " '너무 어려워',\n",
       " '너무 오래 기다리게 한다.',\n",
       " '너무 외로워',\n",
       " '너무 잘하는 후배가 들어왔어',\n",
       " '너무 졸려',\n",
       " '너무 초라해지는 느낌이야',\n",
       " '너무 추워서 나가기 귀찮아',\n",
       " '너무 추워서 시베리아 같아',\n",
       " '너무 편해도 안 좋아',\n",
       " '너무 편해진 거 같아',\n",
       " '너무 허기지네',\n",
       " '너무 힘들다',\n",
       " '너무 힘들다. 지쳤어.',\n",
       " '너무하네 진짜',\n",
       " '넌 고민이 뭐야',\n",
       " '넌 누구냐?',\n",
       " '넘 많이 먹었다.',\n",
       " '넘넘 외로워 죽겠어',\n",
       " '넘어져서 발목 삔 거 같애',\n",
       " '넘어질 뻔했어',\n",
       " '넘어질뻔했어',\n",
       " '네일 할까',\n",
       " '넥타이핀 선물 괜찮겠지?',\n",
       " '넥타이핀 정도는 선물로 줘도 괜찮겠지?',\n",
       " '노는게 제일 좋아',\n",
       " '노래 못해서 노래방 안 가',\n",
       " '노래 잘 부르는 사람 부러워',\n",
       " '노래 잘하고 싶어',\n",
       " '노래 잘하는 사람 부러워',\n",
       " '노래방 가고 싶어',\n",
       " '노래방 가면 어색할까',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d97980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6124a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c472866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8170]\n",
      "END_TOKEN의 번호 : [8171]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4613e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e777497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5759, 607, 2490, 4160]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2353, 7510, 5, 6273, 94, 7960]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725d061",
   "metadata": {},
   "source": [
    "### 적절한 패딩 길이 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf0656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bd4518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 길이 평균: 12.879049310665652\n",
      "토큰 길이 최대: 56\n",
      "토큰 길이 표준편차: 6.167205838440642\n"
     ]
    }
   ],
   "source": [
    "num_questions = [len(tokens) for tokens in questions]\n",
    "num_questions = np.array(num_questions)\n",
    "\n",
    "\n",
    "# 평균값, 최댓값, 표준편차\n",
    "print(f\"토큰 길이 평균: {np.mean(num_questions)}\")\n",
    "print(f\"토큰 길이 최대: {np.max(num_questions)}\")\n",
    "print(f\"토큰 길이 표준편차: {np.std(num_questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2989512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 길이 평균: 15.0151399813922\n",
      "토큰 길이 최대: 76\n",
      "토큰 길이 표준편차: 6.70155143772292\n"
     ]
    }
   ],
   "source": [
    "num_answers = [len(tokens) for tokens in answers]\n",
    "num_answers = np.array(num_answers)\n",
    "\n",
    "\n",
    "# 평균값, 최댓값, 표준편차\n",
    "print(f\"토큰 길이 평균: {np.mean(num_answers)}\")\n",
    "print(f\"토큰 길이 최대: {np.max(num_answers)}\")\n",
    "print(f\"토큰 길이 표준편차: {np.std(num_answers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbabfdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('all text length')\n",
    "plt.hist(num_answers, bins=100)\n",
    "plt.hist(num_questions, bins=100)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c151e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_length = 40\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "        \n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d30bc983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9924722997547154\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(select_length, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e616fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9984775437706166\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(select_length, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98b3331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd0aa4",
   "metadata": {},
   "source": [
    "### 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b2ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2ea2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8172\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cc794",
   "metadata": {},
   "source": [
    "### train data와 validation data로 나누어서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88907b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# BATCH_SIZE와 BUFFER_SIZE 정의\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 질문과 답변 데이터를 tf.data.Dataset으로 만듭니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "# 전체 데이터셋 크기 계산\n",
    "dataset_size = len(questions)\n",
    "\n",
    "# 학습 데이터셋과 검증 데이터셋 크기 계산\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# 데이터셋 캐싱, 셔플링, 배칭 및 prefetch 적용\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# 학습 데이터셋과 검증 데이터셋으로 분할\n",
    "train_dataset = dataset.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = dataset.skip(train_size).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8ed8a",
   "metadata": {},
   "source": [
    "## Transformer 모델 구성하기\n",
    "\n",
    "추가적으로 모델 저장을 위해 `get_config()`와 `__init__`부분을 수정하였다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20711e02",
   "metadata": {},
   "source": [
    "- 모델 선정 이유\n",
    "    >- transformer는 자연어 처리 작업에서 좋은 성능을 발휘하는 것으로 알려져 있다.\n",
    "    >- 특히 문장의 길이에 관계없이 문맥을 잘 이해하고 다룰 수 있는 능력이 강점이다. \n",
    "\n",
    "- Metrics 선정 이유\n",
    "    >- 모델이 생성한 문장이 정확하게 의미를 전달하는지를 중요하게 여기기 때문에 accuracy 메트릭을 사용했다.\n",
    "    >- 이 메트릭은 모델이 단어 수준에서 얼마나 정확하게 예측하는지를 측정한다. \n",
    "    >- 이 외에도 BLEU나 ROUGE 등의 자동 평가 지표를 사용하여 모델의 출력을 사람이 직접 평가하는 경우와 비교할 수도 있다.\n",
    "\n",
    "- Loss 선정 이유\n",
    "    >- 우리가 다루는 과제는 문장 생성 문제이며, 희소한 출력 공간에서 정확한 단어를 예측하는 것이 중요하다. \n",
    "    >- 이를 위해 sparse categorical crossentropy 손실 함수를 선택했다. \n",
    "    >- 이 함수는 다중 클래스 분류 문제에서 주로 사용되며, 우리의 출력이 정수 형태의 토큰 ID로 표현되기 때문에 적합하다. \n",
    "    >- 또한, 패딩된 부분을 무시하기 위한 mask를 적용하여 모델이 패딩 토큰을 무시하도록 했다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c61f0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.position = position\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEncoding, self).get_config()\n",
    "        config.update({\n",
    "            'position': self.position,\n",
    "            'd_model': self.d_model\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcbe484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d4fba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_heads': self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "393533e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dacf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),)([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ea4cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    #################################################\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션) #\n",
    "    ################################################\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    ##############################################################\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션) #\n",
    "    ##############################################################\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    ##################################\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층 #\n",
    "    #################################\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9ce2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5542ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3146240     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3673600     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   2100204     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,920,044\n",
      "Trainable params: 8,920,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "590f0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247cde75",
   "metadata": {},
   "source": [
    "### 커스텀 된 학습률(Learning rate)\n",
    "\n",
    "$$ lrate = d^{-0.5}_{model} \\cdot min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d884a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'd_model': int(self.d_model.numpy()),\n",
    "            'warmup_steps': self.warmup_steps,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "815a0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CustomSchedule 클래스 정의\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)  # Ensure step is a float tensor\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf404e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def63134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 33s 69ms/step - loss: 1.4788 - accuracy: 0.0234 - val_loss: 1.3484 - val_accuracy: 0.0481\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34837, saving model to ./checkpoints/cp-0001.ckpt\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 1.2575 - accuracy: 0.0482 - val_loss: 1.1320 - val_accuracy: 0.0496\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34837 to 1.13197, saving model to ./checkpoints/cp-0002.ckpt\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 1.0668 - accuracy: 0.0498 - val_loss: 0.9914 - val_accuracy: 0.0502\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13197 to 0.99136, saving model to ./checkpoints/cp-0003.ckpt\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.9742 - accuracy: 0.0516 - val_loss: 0.9096 - val_accuracy: 0.0534\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.99136 to 0.90961, saving model to ./checkpoints/cp-0004.ckpt\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.9148 - accuracy: 0.0550 - val_loss: 0.8905 - val_accuracy: 0.0569\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90961 to 0.89047, saving model to ./checkpoints/cp-0005.ckpt\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.8734 - accuracy: 0.0575 - val_loss: 0.8135 - val_accuracy: 0.0603\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89047 to 0.81351, saving model to ./checkpoints/cp-0006.ckpt\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.8273 - accuracy: 0.0607 - val_loss: 0.7721 - val_accuracy: 0.0650\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.81351 to 0.77213, saving model to ./checkpoints/cp-0007.ckpt\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.7765 - accuracy: 0.0649 - val_loss: 0.7042 - val_accuracy: 0.0699\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.77213 to 0.70418, saving model to ./checkpoints/cp-0008.ckpt\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.7164 - accuracy: 0.0700 - val_loss: 0.6258 - val_accuracy: 0.0781\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.70418 to 0.62575, saving model to ./checkpoints/cp-0009.ckpt\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.6607 - accuracy: 0.0771 - val_loss: 0.5640 - val_accuracy: 0.0872\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.62575 to 0.56398, saving model to ./checkpoints/cp-0010.ckpt\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.5937 - accuracy: 0.0839 - val_loss: 0.4961 - val_accuracy: 0.0961\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.56398 to 0.49607, saving model to ./checkpoints/cp-0011.ckpt\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.5300 - accuracy: 0.0918 - val_loss: 0.4272 - val_accuracy: 0.1044\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.49607 to 0.42717, saving model to ./checkpoints/cp-0012.ckpt\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.4638 - accuracy: 0.0998 - val_loss: 0.3506 - val_accuracy: 0.1143\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42717 to 0.35055, saving model to ./checkpoints/cp-0013.ckpt\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.3967 - accuracy: 0.1080 - val_loss: 0.2866 - val_accuracy: 0.1243\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35055 to 0.28657, saving model to ./checkpoints/cp-0014.ckpt\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.3328 - accuracy: 0.1170 - val_loss: 0.2243 - val_accuracy: 0.1342\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.28657 to 0.22431, saving model to ./checkpoints/cp-0015.ckpt\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.2758 - accuracy: 0.1262 - val_loss: 0.1691 - val_accuracy: 0.1454\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22431 to 0.16914, saving model to ./checkpoints/cp-0016.ckpt\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.2238 - accuracy: 0.1344 - val_loss: 0.1318 - val_accuracy: 0.1510\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16914 to 0.13184, saving model to ./checkpoints/cp-0017.ckpt\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.1750 - accuracy: 0.1417 - val_loss: 0.0877 - val_accuracy: 0.1576\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13184 to 0.08769, saving model to ./checkpoints/cp-0018.ckpt\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.1382 - accuracy: 0.1484 - val_loss: 0.0633 - val_accuracy: 0.1629\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08769 to 0.06326, saving model to ./checkpoints/cp-0019.ckpt\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.1088 - accuracy: 0.1537 - val_loss: 0.0448 - val_accuracy: 0.1667\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06326 to 0.04484, saving model to ./checkpoints/cp-0020.ckpt\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0852 - accuracy: 0.1580 - val_loss: 0.0327 - val_accuracy: 0.1673\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04484 to 0.03272, saving model to ./checkpoints/cp-0021.ckpt\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0685 - accuracy: 0.1607 - val_loss: 0.0274 - val_accuracy: 0.1701\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03272 to 0.02742, saving model to ./checkpoints/cp-0022.ckpt\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0589 - accuracy: 0.1622 - val_loss: 0.0222 - val_accuracy: 0.1679\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02742 to 0.02215, saving model to ./checkpoints/cp-0023.ckpt\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0523 - accuracy: 0.1626 - val_loss: 0.0193 - val_accuracy: 0.1705\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02215 to 0.01926, saving model to ./checkpoints/cp-0024.ckpt\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0469 - accuracy: 0.1637 - val_loss: 0.0191 - val_accuracy: 0.1701\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01926 to 0.01915, saving model to ./checkpoints/cp-0025.ckpt\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0459 - accuracy: 0.1646 - val_loss: 0.0173 - val_accuracy: 0.1718\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01915 to 0.01726, saving model to ./checkpoints/cp-0026.ckpt\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0433 - accuracy: 0.1647 - val_loss: 0.0162 - val_accuracy: 0.1686\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01726 to 0.01620, saving model to ./checkpoints/cp-0027.ckpt\n",
      "Epoch 28/50\n",
      "139/148 [===========================>..] - ETA: 0s - loss: 0.0388 - accuracy: 0.1655"
     ]
    }
   ],
   "source": [
    "# 체크포인트 콜백 정의\n",
    "checkpoint_path = \"./checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델 체크포인트 콜백 생성\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7eccd3",
   "metadata": {},
   "source": [
    "### Loss와 Accuracy 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c004fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8d63d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history에서 손실과 정확도, 검증 손실과 검증 정확도를 추출합니다.\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc, 'ro', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "556fc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence, model, num):\n",
    "    sentence = preprocess_sentence(sentence, num)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c08ccd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence, model, num=False):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence, model, num)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aca8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(questions + answers)\n",
    "# total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# input_sequences = []\n",
    "# for line in questions + answers:\n",
    "#     token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "#     for i in range(1, len(token_list)):\n",
    "#         n_gram_sequence = token_list[:i+1]\n",
    "#         input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf32269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 패딩과 입력, 출력 분리\n",
    "# max_sequence_len = max([len(x) for x in input_sequences])\n",
    "# input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "# y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2868e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습 및 검증 데이터 분리\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c8d6f",
   "metadata": {},
   "source": [
    "### 3. GPT-1 modeling (시도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff473ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Embedding, Dense, Input, GlobalAveragePooling1D, MultiHeadAttention, LayerNormalization, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# # GPT-1은 Transformer의 Decoder 블록만을 사용한다. \n",
    "# # 따라서 Encoder 블록을 제거하고, Decoder만으로 모델을 구성해야 한다.\n",
    "# # GPT-1은 학습 중 마스크된 멀티 헤드 어텐션을 사용한다. 따라서 입력 시퀀스의 다음 단어를 예측하는 방식으로 입력 블럭 역시 수정되어야 한다.\n",
    "# # GPT-1의 Decoder 블록을 구성하고, 이를 사용해 모델을 학습하겠다.\n",
    "# def gpt_model(vocab_size, max_len, num_layers, units, d_model, num_heads, dropout):\n",
    "#     inputs = Input(shape=(max_len,))\n",
    "#     # 임베딩 레이어\n",
    "#     embedding_layer = Embedding(vocab_size, d_model)\n",
    "#     x = embedding_layer(inputs)\n",
    "#     # Transformer의 Decoder 부분만 사용하여 GPT-1 model을 구성한다.\n",
    "#     for _ in range(num_layers):\n",
    "#         # 멀티 헤드 어텐션\n",
    "#         attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x, x)\n",
    "#         attn_output = Dropout(dropout)(attn_output)\n",
    "#         out1 = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "#         # 포지셔널 피드포워드 네트워크\n",
    "#         ffn_output = Dense(units, activation='relu')(out1)\n",
    "#         ffn_output = Dense(d_model)(ffn_output)\n",
    "#         ffn_output = Dropout(dropout)(ffn_output)\n",
    "#         x = LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "#     # 평균 풀링 후 출력 레이어\n",
    "#     x = GlobalAveragePooling1D()(x)\n",
    "#     outputs = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "#     return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fcc62b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 27, 128)      3107584     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 27, 128)      263808      embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 27, 128)      0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 27, 128)      0           embedding[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 27, 128)      256         tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 27, 256)      33024       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 27, 128)      32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 27, 128)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 27, 128)      0           layer_normalization[0][0]        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 27, 128)      256         tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 27, 128)      263808      layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 27, 128)      0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 27, 128)      0           layer_normalization_1[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 27, 128)      256         tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 27, 256)      33024       layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 27, 128)      32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 27, 128)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 27, 128)      0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 27, 128)      256         tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24278)        3131862     global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 6,899,926\n",
      "Trainable params: 6,899,926\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # 하이퍼파라미터 설정\n",
    "# num_layers = 2\n",
    "# d_model = 128\n",
    "# num_heads = 4\n",
    "# units = 256\n",
    "# dropout = 0.1\n",
    "\n",
    "# # GPT-1 모델 생성\n",
    "# model = gpt_model(total_words, max_sequence_len-1, num_layers, units, d_model, num_heads, dropout)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a6116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# # 모델 학습\n",
    "# history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습 결과 시각화\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(X_val,  y_val, verbose=2)\n",
    "# print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ad9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 텍스트 생성 함수\n",
    "# def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "#     for _ in range(next_words):\n",
    "#         token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "#         token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "#         predicted = model.predict(token_list, verbose=0)\n",
    "#         predicted_word = tokenizer.index_word[np.argmax(predicted)]\n",
    "#         seed_text += \" \" + predicted_word\n",
    "#     return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예시 텍스트 생성\n",
    "# seed_text = \"안녕하세요\"\n",
    "# next_words = 10\n",
    "# generated_text = generate_text(seed_text, next_words, model, max_sequence_len)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4d259",
   "metadata": {},
   "source": [
    "## Q1. GPT model 생성 ( 본 Quest 정답 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99630550",
   "metadata": {},
   "source": [
    "\n",
    "- Tranformer와 비교해 변경이 필요한 부분 (입력 블럭)\n",
    "    >- GPT-1의 입력 블록을 단일 시퀸스 입력으로 처리하도록 변경해야 한다(주로 텍스트 생성을 위한 언어 모델이므로).\n",
    "    >- 기존의 Encoder-Decoder 구조에서 Encoder를 제거하고 Decoder만 사용해야 한다.\n",
    "    >- 따라서 기존의 inputs와 dec_inputs를 단일 inputs로 변경하였고, enc_padding_mask와 dec_padding_mask를 제거하고, 대신 look_ahead_mask를 사용하였다.\n",
    "\n",
    "- Tranformer와 비교해 변경이 필요한 부분 (모델 아키텍처)\n",
    "    >- 학습 중 마스크된 멀티 헤드 어텐션을 사용한다\n",
    "    >- 입력을 받아 단일 시퀀스 출력으로 변환해야 한다.\n",
    "    >- 기존의 encoder 블록을 제거하고, decoder 블록만 사용하도록 변경한 뒤 inputs를 그대로 decoder 블록의 입력으로 사용하였다.\n",
    "\n",
    "- Tranformer와 비교해 변경이 필요한 부분 (출력 블럭)\n",
    "    >- 출력 블록은 다음 토큰을 예측하는 형태로 변경해야 한다.\n",
    "    >- decoder의 출력에 대해 다음 토큰을 예측하도록 Dense 레이어를 적용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e7dd9",
   "metadata": {},
   "source": [
    "## Q2. GPT modeling process (include preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "70cecf93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd10e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da513fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "# 데이터 로드 및 전처리\n",
    "\n",
    "data = pd.read_csv('~/aiffel/transformer_chatbot/data/ChatbotData .csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7613e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence, num=True):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    if num == False:\n",
    "        sentence = re.sub(r'[^가-힣a-zA-Z.?!,]', ' ', sentence)\n",
    "    else:\n",
    "        sentence = re.sub(r'[^가-힣0-9a-zA-Z.?!,]', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0edf1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입출력을 합친 모든 문장을 가진 리스트를 만듦\n",
    "all_sentences = pd.concat([data[\"Q\"], data[\"A\"]]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c72a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(sentences):\n",
    "    return [preprocess_sentence(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e16ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocess_sentences(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0bf3c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8166\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(dataset, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)\n",
    "\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3b651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(sentences):\n",
    "    tokenized_outputs = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN\n",
    "        if len(sentence) <= MAX_LENGTH:\n",
    "            tokenized_outputs.append(sentence)\n",
    "\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6f04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tokenize_and_filter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6e15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look-ahead 마스크 생성\n",
    "look_ahead_mask = create_look_ahead_mask(dataset[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40a712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff1b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd62b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터를 tf.data.Dataset으로 만듭니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': data[:, :-1],\n",
    "        'look_ahead_mask': look_ahead_mask,\n",
    "    },\n",
    "    {\n",
    "        'outputs': data[:, 1:]\n",
    "    },\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52816b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ({inputs: (39,), look_ahead_mask: (1, 39, 39)}, {outputs: (39,)}), types: ({inputs: tf.int32, look_ahead_mask: tf.float32}, {outputs: tf.int32})>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ed37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "train_dataset = dataset.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = dataset.skip(train_size).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa287801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-1 모델 구성\n",
    "MAX_LENGTH = 40\n",
    "VOCAB_SIZE = 10000\n",
    "NUM_LAYERS = 4\n",
    "D_MODEL = 128\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a731da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.position = position\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "                                     i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "                                     d_model=d_model)\n",
    "\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "        \n",
    "        pos_encoding = angle_rads[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99496b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Dot-Product Attention\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a0518bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리 복수 생성\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        \n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후, 각 결과를 다시 연결\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 적용\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1107153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Wise Feed Forward Network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8180e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Layer\n",
    "def decoder_gpt_layer(units, d_model, num_heads, dropout, name=\"decoder_gpt_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "#     padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs = {'query': inputs,'key': inputs,'value': inputs, 'mask': look_ahead_mask})\n",
    "    \n",
    "    \n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37047d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63167f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "def decoder_gpt(vocab_size, num_layers, units, d_model, num_heads, dropout, name='decoder_gpt'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "#     padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    \n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(dropout)(embeddings)\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_gpt_layer(\n",
    "            units=units, d_model=d_model, num_heads=num_heads, dropout=dropout, \n",
    "                                name='decoder_gpt_layer_{}'.format(i))(inputs=[outputs, look_ahead_mask])    \n",
    "    \n",
    "    logits = tf.keras.layers.Dense(vocab_size, name='outputs')(outputs)    \n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, look_ahead_mask],\n",
    "        outputs=logits,\n",
    "        name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b87a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "639fb9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_gpt\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    2560000     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, None, 256)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding (Positional (None, None, 256)    0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 256)    0           positional_encoding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (InputLayer)    [(None, 1, None, Non 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gpt_layer_0 (Functional (None, None, 256)    527104      dropout[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gpt_layer_1 (Functional (None, None, 256)    527104      decoder_gpt_layer_0[0][0]        \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 10000)  2570000     decoder_gpt_layer_1[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 6,184,208\n",
      "Trainable params: 6,184,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = decoder_gpt(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e5f385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e22f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomSchedule 클래스 정의 및 학습률 스케줄 설정\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6641a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12e53de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 옵티마이저 정의\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# 정확도 메트릭 정의\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9ab5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "296/296 [==============================] - 17s 47ms/step - loss: 1.4185 - accuracy: 0.0211 - val_loss: 1.2289 - val_accuracy: 0.0261\n",
      "Epoch 2/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 1.1229 - accuracy: 0.0348 - val_loss: 1.0554 - val_accuracy: 0.0381\n",
      "Epoch 3/30\n",
      "296/296 [==============================] - 14s 47ms/step - loss: 1.0256 - accuracy: 0.0394 - val_loss: 0.9690 - val_accuracy: 0.0424\n",
      "Epoch 4/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.9645 - accuracy: 0.0431 - val_loss: 0.9110 - val_accuracy: 0.0466\n",
      "Epoch 5/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.9009 - accuracy: 0.0470 - val_loss: 0.8432 - val_accuracy: 0.0507\n",
      "Epoch 6/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.8413 - accuracy: 0.0511 - val_loss: 0.7672 - val_accuracy: 0.0578\n",
      "Epoch 7/30\n",
      "296/296 [==============================] - 13s 46ms/step - loss: 0.7767 - accuracy: 0.0561 - val_loss: 0.6857 - val_accuracy: 0.0641\n",
      "Epoch 8/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.7146 - accuracy: 0.0611 - val_loss: 0.6179 - val_accuracy: 0.0700\n",
      "Epoch 9/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.6544 - accuracy: 0.0658 - val_loss: 0.5570 - val_accuracy: 0.0791\n",
      "Epoch 10/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.6008 - accuracy: 0.0715 - val_loss: 0.4959 - val_accuracy: 0.0860\n",
      "Epoch 11/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.5542 - accuracy: 0.0767 - val_loss: 0.4488 - val_accuracy: 0.0921\n",
      "Epoch 12/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.5147 - accuracy: 0.0817 - val_loss: 0.4158 - val_accuracy: 0.1002\n",
      "Epoch 13/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.4847 - accuracy: 0.0866 - val_loss: 0.3848 - val_accuracy: 0.1035\n",
      "Epoch 14/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.4596 - accuracy: 0.0913 - val_loss: 0.3626 - val_accuracy: 0.1094\n",
      "Epoch 15/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.4320 - accuracy: 0.0962 - val_loss: 0.3457 - val_accuracy: 0.1146\n",
      "Epoch 16/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.4069 - accuracy: 0.1015 - val_loss: 0.3294 - val_accuracy: 0.1156\n",
      "Epoch 17/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3873 - accuracy: 0.1051 - val_loss: 0.3184 - val_accuracy: 0.1189\n",
      "Epoch 18/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3742 - accuracy: 0.1077 - val_loss: 0.3112 - val_accuracy: 0.1194\n",
      "Epoch 19/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3622 - accuracy: 0.1100 - val_loss: 0.3053 - val_accuracy: 0.1202\n",
      "Epoch 20/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3535 - accuracy: 0.1122 - val_loss: 0.3012 - val_accuracy: 0.1198\n",
      "Epoch 21/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3460 - accuracy: 0.1129 - val_loss: 0.2980 - val_accuracy: 0.1211\n",
      "Epoch 22/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3407 - accuracy: 0.1142 - val_loss: 0.2960 - val_accuracy: 0.1235\n",
      "Epoch 23/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3367 - accuracy: 0.1151 - val_loss: 0.2937 - val_accuracy: 0.1230\n",
      "Epoch 24/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3329 - accuracy: 0.1160 - val_loss: 0.2923 - val_accuracy: 0.1228\n",
      "Epoch 25/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3293 - accuracy: 0.1163 - val_loss: 0.2900 - val_accuracy: 0.1245\n",
      "Epoch 26/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3266 - accuracy: 0.1169 - val_loss: 0.2903 - val_accuracy: 0.1216\n",
      "Epoch 27/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3250 - accuracy: 0.1176 - val_loss: 0.2874 - val_accuracy: 0.1235\n",
      "Epoch 28/30\n",
      "296/296 [==============================] - 13s 46ms/step - loss: 0.3225 - accuracy: 0.1173 - val_loss: 0.2862 - val_accuracy: 0.1232\n",
      "Epoch 29/30\n",
      "296/296 [==============================] - 13s 46ms/step - loss: 0.3205 - accuracy: 0.1177 - val_loss: 0.2870 - val_accuracy: 0.1252\n",
      "Epoch 30/30\n",
      "296/296 [==============================] - 14s 46ms/step - loss: 0.3185 - accuracy: 0.1185 - val_loss: 0.2854 - val_accuracy: 0.1255\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bd6a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# 손실과 정확도 시각화\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history.history.get('accuracy', [])\n",
    "val_acc = history.history.get('val_accuracy', [])\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7740ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc, 'ro', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c54a321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a532e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5066edf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbf10fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0b1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d58270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a152c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5edf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
